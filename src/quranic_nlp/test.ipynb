{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "df = pd.read_csv(utils.MORPHOLOGY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "df[(df['soure'] == 5 - 1) & (df['ayeh'] == 5 - 1)]\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "gb_soure = df.groupby('soure')\n",
    "gb_soure = [gb_soure.get_group(x) for x in gb_soure.groups]\n",
    "df2 = gb_soure[5 - 1]\n",
    "\n",
    "gb = df2.groupby('ayeh')\n",
    "gb = [gb.get_group(x) for x in gb.groups]\n",
    "data = gb[5 - 1]\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lang_trans.arabic import buckwalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data_utils/morphology_0.62.txt') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = {'soure':[], 'ayeh':[], 'word':[], 'Tag':[], 'Lemma':[], 'Root':[]}\n",
    "for data in text.split('\\n')[1:]:\n",
    "    ex = data.split('\\t')\n",
    "    location = ex[0][1:-1].split(':')\n",
    "    word = buckwalter.untransliterate(ex[2])\n",
    "    tag = ex[3]\n",
    "    feat = ex[4].split('|')\n",
    "    lemma = ''\n",
    "    root = ''\n",
    "    for f in feat:\n",
    "        if f.startswith('LEM:'):\n",
    "            lemma = buckwalter.untransliterate(f[4:])\n",
    "        if f.startswith('ROOT:'):\n",
    "            root = buckwalter.untransliterate(f[5:])\n",
    "    \n",
    "    feature['soure'].append(location[0])\n",
    "    feature['ayeh'].append(location[1])\n",
    "    feature['word'].append(word)\n",
    "    feature['Tag'].append(tag)\n",
    "    \n",
    "    feature['Lemma'].append(lemma)\n",
    "    feature['Root'].append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(feature).to_csv('morphologhy.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('./data/morphologhy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_soure = df.groupby('soure')\n",
    "gb_soure = [gb_soure.get_group(x) for x in gb_soure.groups]\n",
    "temp = gb_soure[0]\n",
    "\n",
    "gb = temp.groupby('ayeh')\n",
    "gb = [gb.get_group(x) for x in gb.groups]\n",
    "data = gb[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language\n",
    "\n",
    "translation_translator = 'fa#1'\n",
    "# pips = 'dep,pos,root,lemma'\n",
    "pips = ''\n",
    "nlp = language.Pipeline(pips, translation_translator)\n",
    "\n",
    "doc = nlp('1#1')\n",
    "\n",
    "print(doc)\n",
    "print(doc._.text)\n",
    "print(doc._.surah)\n",
    "print(doc._.ayah)\n",
    "print(doc._.revelation_order)\n",
    "print(doc._.sim_ayahs)\n",
    "print(doc._.translations)\n",
    "print(doc._.hadiths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language\n",
    "\n",
    "translation_translator = 'fa#1'\n",
    "pips = 'dep,pos,root,lemma'\n",
    "# pips = ''\n",
    "nlp = language.Pipeline(pips, translation_translator)\n",
    "\n",
    "doc = nlp('اللَّهِ الرَّحْمَنِ')\n",
    "\n",
    "print(doc)\n",
    "print(doc._.text)\n",
    "print(doc._.surah)\n",
    "print(doc._.ayah)\n",
    "print(doc._.revelation_order)\n",
    "print(doc._.sim_ayahs)\n",
    "print(doc._.translations)\n",
    "print(doc._.hadiths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=doc[2]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word.pos_)\n",
    "import utils\n",
    "print(utils.POS_UNI_FA[word.pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word._.dep_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word._.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "2\n",
      "Error to get hadiths\n",
      "وَ الْکِتَابِ الْمُبِینِ \n",
      "وَالْكِتَابِ الْمُبِينِ\n",
      "زخرف\n",
      "2\n",
      "39\n",
      "['44#2', '28#2', '26#2', '12#1', '37#117', '27#1', '27#75', '5#15', '11#6', '75#19', '36#17', '37#106', '15#89', '16#64', '15#1', '81#23', '16#82', '52#2', '31#2', '34#3', '98#3', '83#20', '83#9', '37#156', '26#115', '6#59', '27#79', '2#176', '36#24', '3#78', '3#48', '10#61', '56#78', '23#49', '29#47', '46#2', '45#2', '39#1', '10#1', '28#52', '68#37', '69#19', '98#4', '40#2', '3#23', '4#136', '6#16', '16#89', '3#187', '69#25', '26#195', '3#3', '4#153', '2#2', '2#53', '6#114', '84#7', '32#2', '24#25', '43#4', '37#15', '45#30', '64#12', '62#2', '3#70', '19#41', '13#43', '98#1', '29#18', '19#56', '26#97', '71#2', '37#157', '35#40', '2#282', '6#7', '40#53', '40#70', '3#184', '48#1', '2#101', '3#79', '2#79', '15#79', '78#29', '25#35', '19#30', '26#30', '7#196', '35#31', '3#164', '5#92', '18#49', '2#159', '5#48', '39#2', '38#70', '19#12', '83#18', '40#23']\n",
      "سوگند به اين كتاب روشنگر.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import language\n",
    "\n",
    "translation_translator = 'fa#1'\n",
    "pips = 'dep,pos,root,lemma'\n",
    "# pips = 'dep, root, lemma'\n",
    "nlp = language.Pipeline(pips, translation_translator)\n",
    "\n",
    "# doc = nlp('فَاسْتَمْسِكْ بِالَّذِي أُوحِيَ إِلَيْكَ ۖ إِنَّكَ عَلَىٰ صِرَاطٍ مُّسْتَقِيمٍ')\n",
    "doc = nlp('وَالْكِتَابِ الْمُبِينِ')\n",
    "\n",
    "print(doc)\n",
    "print(doc._.text)\n",
    "print(doc._.surah)\n",
    "print(doc._.ayah)\n",
    "print(doc._.revelation_order)\n",
    "print(doc._.sim_ayahs)\n",
    "print(doc._.translations)\n",
    "print(doc._.hadiths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language\n",
    "\n",
    "translation_translator = 'fa#1'\n",
    "pips = 'dep,pos,root,lemma'\n",
    "nlp = language.Pipeline(pips, translation_translator)\n",
    "\n",
    "doc = nlp('3#200')\n",
    "\n",
    "print(doc)\n",
    "print(doc._.text)\n",
    "print(doc._.surah)\n",
    "print(doc._.ayah)\n",
    "print(doc._.revelation_order)\n",
    "print(doc._.sim_ayahs)\n",
    "print(doc._.translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=doc[2]\n",
    "print(word)\n",
    "print(word.dep_)\n",
    "print(word.head)\n",
    "print(word.lemma_)\n",
    "print(word.pos_)\n",
    "print(word._.dep_arc)\n",
    "print(word._.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "print(utils.POS_UNI_FA['NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = language.to_json(pips, doc)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "options = {\"compact\": True, \"bg\": \"#09a3d5\",\n",
    "           \"color\": \"white\", \"font\": \"xb-niloofar\"}\n",
    "displacy.serve(doc, style=\"dep\", options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data_utils/roku3at.txt') as file:\n",
    "    data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].split('\\t')[0].split('##')[1]\n",
    "# data[0].split('\\t')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-1].split('\\t')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('../../data_utils/Topic_Word_Percentage_Verse_Lemma_with_stopWords_Removal_Mallet_20230619213545.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('../../data_utils/Verse_Topic_Percentage_Verse_Lemma_with_stopWords_Removal_Mallet_20230619213542.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
